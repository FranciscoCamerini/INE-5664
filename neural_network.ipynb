{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Análise e Implementação de Rede Neural para Tarefas de Predição\n",
    "\n",
    "## Objetivo do Projeto\n",
    "\n",
    "Este notebook detalha a implementação de uma rede neural do zero em Python, utilizando a biblioteca NumPy para as operações fundamentais. O objetivo é construir e avaliar três modelos preditivos para as seguintes tarefas, conforme os requisitos do projeto:\n",
    "1.  **Regressão:** Prever a taxa de defeitos (`DefectRate`).\n",
    "2.  **Classificação Binária:** Prever o status do defeito (`DefectStatus`).\n",
    "3.  **Classificação Multiclasse:** Prever o nível do defeito (`DefectLevel`).\n",
    "\n",
    "O projeto também inclui a implementação de múltiplas funções de ativação e de perda, bem como o algoritmo de backpropagation para treinamento da rede."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Funções de Ativação e suas Derivadas ---\n",
    "\n",
    "def sigmoid(x):\n",
    "    x = np.clip(x, -500, 500)\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def sigmoid_derivative(a):\n",
    "    return a * (1 - a)\n",
    "\n",
    "def relu(x):\n",
    "    return np.maximum(0, x)\n",
    "\n",
    "def relu_derivative(x):\n",
    "    return (x > 0).astype(float)\n",
    "\n",
    "def tanh(x):\n",
    "    return np.tanh(x)\n",
    "\n",
    "def tanh_derivative(a):\n",
    "    return 1 - np.square(a)\n",
    "\n",
    "activation_functions = {\n",
    "    \"sigmoid\": (sigmoid, sigmoid_derivative),\n",
    "    \"relu\": (relu, relu_derivative),\n",
    "    \"tanh\": (tanh, tanh_derivative),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Funções de Perda e suas Derivadas ---\n",
    "\n",
    "def mse(y_true, y_pred):\n",
    "    return np.mean(np.square(y_true - y_pred))\n",
    "\n",
    "def mse_derivative(y_true, y_pred):\n",
    "    return y_pred - y_true\n",
    "\n",
    "def binary_cross_entropy(y_true, y_pred, epsilon=1e-12):\n",
    "    y_pred = np.clip(y_pred, epsilon, 1 - epsilon)\n",
    "    return -np.mean(y_true * np.log(y_pred) + (1 - y_true) * np.log(1 - y_pred))\n",
    "\n",
    "def bce_derivative(y_true, y_pred, epsilon=1e-12):\n",
    "    y_pred = np.clip(y_pred, epsilon, 1 - epsilon)\n",
    "    return (y_pred - y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Classe Principal da Rede Neural ---\n",
    "\n",
    "class NeuralNetwork:\n",
    "    def __init__(self, layers, activation=\"sigmoid\", loss_func=mse, loss_derivative=mse_derivative):\n",
    "        self.layers = layers\n",
    "        self.activation, self.activation_derivative = activation_functions[activation]\n",
    "        self.loss = loss_func\n",
    "        self.loss_derivative = loss_derivative\n",
    "        self._initialize_weights()\n",
    "\n",
    "    def _initialize_weights(self):\n",
    "        self.weights = []\n",
    "        self.biases = []\n",
    "        for i in range(len(self.layers) - 1):\n",
    "            if self.activation.__name__ == 'relu':\n",
    "                W = np.random.randn(self.layers[i], self.layers[i + 1]) * np.sqrt(2. / self.layers[i])\n",
    "            else:\n",
    "                W = np.random.randn(self.layers[i], self.layers[i + 1]) * np.sqrt(1. / self.layers[i])\n",
    "            b = np.zeros((1, self.layers[i + 1]))\n",
    "            self.weights.append(W)\n",
    "            self.biases.append(b)\n",
    "\n",
    "    def forward(self, X):\n",
    "        self.a = [X]\n",
    "        for i in range(len(self.weights)):\n",
    "            z = np.dot(self.a[i], self.weights[i]) + self.biases[i]\n",
    "            if i < len(self.weights) - 1:\n",
    "                a = self.activation(z)\n",
    "            else: # Camada de saída\n",
    "                a = z\n",
    "                if self.loss.__name__ == 'binary_cross_entropy':\n",
    "                    a = sigmoid(z) \n",
    "            self.a.append(a)\n",
    "        return self.a[-1]\n",
    "\n",
    "    def backward(self, X, y, learning_rate):\n",
    "        m = X.shape[0]\n",
    "\n",
    "        if self.loss.__name__ == 'binary_cross_entropy':\n",
    "            dz_last = self.a[-1] - y \n",
    "        else:\n",
    "            da_last = self.loss_derivative(y, self.a[-1])\n",
    "            dz_last = da_last * self.activation_derivative(self.a[-1])\n",
    "\n",
    "        dw_last = np.dot(self.a[-2].T, dz_last) / m\n",
    "        db_last = np.sum(dz_last, axis=0, keepdims=True) / m\n",
    "\n",
    "        self.weights[-1] -= learning_rate * dw_last\n",
    "        self.biases[-1] -= learning_rate * db_last\n",
    "\n",
    "        dz_next = dz_last\n",
    "        \n",
    "        for i in reversed(range(len(self.weights) - 1)):\n",
    "\n",
    "            da_current = np.dot(dz_next, self.weights[i + 1].T)\n",
    "\n",
    "            dz_current = da_current * self.activation_derivative(self.a[i + 1])\n",
    "            \n",
    "            dw_current = np.dot(self.a[i].T, dz_current) / m\n",
    "            db_current = np.sum(dz_current, axis=0, keepdims=True) / m\n",
    "            \n",
    "            self.weights[i] -= learning_rate * dw_current\n",
    "            self.biases[i] -= learning_rate * db_current\n",
    "            \n",
    "            dz_next = dz_current\n",
    "            \n",
    "    def train(self, X, y, epochs=1000, learning_rate=0.01, verbose=True, print_every=100):\n",
    "        for epoch in range(epochs):\n",
    "            y_pred = self.forward(X)\n",
    "            loss = self.loss(y, y_pred)\n",
    "            self.backward(X, y, learning_rate)\n",
    "            if verbose and epoch % print_every == 0:\n",
    "                print(f\"Epoch {epoch}, Loss: {loss:.4f}\")\n",
    "\n",
    "    def predict(self, X):\n",
    "        return self.forward(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(df, target_column, cols_to_drop=None, test_size=0.2, scale=True, stratify=False):\n",
    "    df_processed = df.copy()\n",
    "\n",
    "    if cols_to_drop:\n",
    "        cols_to_drop_existing = [col for col in cols_to_drop if col in df_processed.columns]\n",
    "        df_processed = df_processed.drop(columns=cols_to_drop_existing)\n",
    "\n",
    "    X = df_processed.drop(columns=[target_column])\n",
    "    y = df_processed[target_column]\n",
    "    \n",
    "    stratify_target = y if stratify else None\n",
    "\n",
    "    if scale:\n",
    "        X = StandardScaler().fit_transform(X)\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=test_size, random_state=42, stratify=stratify_target\n",
    "    )\n",
    "    return X_train, X_test, y_train.values.reshape(-1, 1), y_test.values.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Primeiras 5 linhas do dataset ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ProductionVolume</th>\n",
       "      <th>ProductionCost</th>\n",
       "      <th>SupplierQuality</th>\n",
       "      <th>DeliveryDelay</th>\n",
       "      <th>DefectRate</th>\n",
       "      <th>QualityScore</th>\n",
       "      <th>MaintenanceHours</th>\n",
       "      <th>DowntimePercentage</th>\n",
       "      <th>InventoryTurnover</th>\n",
       "      <th>StockoutRate</th>\n",
       "      <th>WorkerProductivity</th>\n",
       "      <th>SafetyIncidents</th>\n",
       "      <th>EnergyConsumption</th>\n",
       "      <th>EnergyEfficiency</th>\n",
       "      <th>AdditiveProcessTime</th>\n",
       "      <th>AdditiveMaterialCost</th>\n",
       "      <th>DefectStatus</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>202</td>\n",
       "      <td>13175.403783</td>\n",
       "      <td>86.648534</td>\n",
       "      <td>1</td>\n",
       "      <td>3.121492</td>\n",
       "      <td>63.463494</td>\n",
       "      <td>9</td>\n",
       "      <td>0.052343</td>\n",
       "      <td>8.630515</td>\n",
       "      <td>0.081322</td>\n",
       "      <td>85.042379</td>\n",
       "      <td>0</td>\n",
       "      <td>2419.616785</td>\n",
       "      <td>0.468947</td>\n",
       "      <td>5.551639</td>\n",
       "      <td>236.439301</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>535</td>\n",
       "      <td>19770.046093</td>\n",
       "      <td>86.310664</td>\n",
       "      <td>4</td>\n",
       "      <td>0.819531</td>\n",
       "      <td>83.697818</td>\n",
       "      <td>20</td>\n",
       "      <td>4.908328</td>\n",
       "      <td>9.296598</td>\n",
       "      <td>0.038486</td>\n",
       "      <td>99.657443</td>\n",
       "      <td>7</td>\n",
       "      <td>3915.566713</td>\n",
       "      <td>0.119485</td>\n",
       "      <td>9.080754</td>\n",
       "      <td>353.957631</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>960</td>\n",
       "      <td>19060.820997</td>\n",
       "      <td>82.132472</td>\n",
       "      <td>0</td>\n",
       "      <td>4.514504</td>\n",
       "      <td>90.350550</td>\n",
       "      <td>1</td>\n",
       "      <td>2.464923</td>\n",
       "      <td>5.097486</td>\n",
       "      <td>0.002887</td>\n",
       "      <td>92.819264</td>\n",
       "      <td>2</td>\n",
       "      <td>3392.385362</td>\n",
       "      <td>0.496392</td>\n",
       "      <td>6.562827</td>\n",
       "      <td>396.189402</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>370</td>\n",
       "      <td>5647.606037</td>\n",
       "      <td>87.335966</td>\n",
       "      <td>5</td>\n",
       "      <td>0.638524</td>\n",
       "      <td>67.628690</td>\n",
       "      <td>8</td>\n",
       "      <td>4.692476</td>\n",
       "      <td>3.577616</td>\n",
       "      <td>0.055331</td>\n",
       "      <td>96.887013</td>\n",
       "      <td>8</td>\n",
       "      <td>4652.400275</td>\n",
       "      <td>0.183125</td>\n",
       "      <td>8.097496</td>\n",
       "      <td>164.135870</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>206</td>\n",
       "      <td>7472.222236</td>\n",
       "      <td>81.989893</td>\n",
       "      <td>3</td>\n",
       "      <td>3.867784</td>\n",
       "      <td>82.728334</td>\n",
       "      <td>9</td>\n",
       "      <td>2.746726</td>\n",
       "      <td>6.851709</td>\n",
       "      <td>0.068047</td>\n",
       "      <td>88.315554</td>\n",
       "      <td>7</td>\n",
       "      <td>1581.630332</td>\n",
       "      <td>0.263507</td>\n",
       "      <td>6.406154</td>\n",
       "      <td>365.708964</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ProductionVolume  ProductionCost  SupplierQuality  DeliveryDelay  DefectRate  QualityScore  \\\n",
       "0               202    13175.403783        86.648534              1    3.121492     63.463494   \n",
       "1               535    19770.046093        86.310664              4    0.819531     83.697818   \n",
       "2               960    19060.820997        82.132472              0    4.514504     90.350550   \n",
       "3               370     5647.606037        87.335966              5    0.638524     67.628690   \n",
       "4               206     7472.222236        81.989893              3    3.867784     82.728334   \n",
       "\n",
       "   MaintenanceHours  DowntimePercentage  InventoryTurnover  StockoutRate  WorkerProductivity  \\\n",
       "0                 9            0.052343           8.630515      0.081322           85.042379   \n",
       "1                20            4.908328           9.296598      0.038486           99.657443   \n",
       "2                 1            2.464923           5.097486      0.002887           92.819264   \n",
       "3                 8            4.692476           3.577616      0.055331           96.887013   \n",
       "4                 9            2.746726           6.851709      0.068047           88.315554   \n",
       "\n",
       "   SafetyIncidents  EnergyConsumption  EnergyEfficiency  AdditiveProcessTime  \\\n",
       "0                0        2419.616785          0.468947             5.551639   \n",
       "1                7        3915.566713          0.119485             9.080754   \n",
       "2                2        3392.385362          0.496392             6.562827   \n",
       "3                8        4652.400275          0.183125             8.097496   \n",
       "4                7        1581.630332          0.263507             6.406154   \n",
       "\n",
       "   AdditiveMaterialCost  DefectStatus  \n",
       "0            236.439301             1  \n",
       "1            353.957631             1  \n",
       "2            396.189402             1  \n",
       "3            164.135870             1  \n",
       "4            365.708964             1  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Informações do dataset ---\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3240 entries, 0 to 3239\n",
      "Data columns (total 17 columns):\n",
      " #   Column                Non-Null Count  Dtype  \n",
      "---  ------                --------------  -----  \n",
      " 0   ProductionVolume      3240 non-null   int64  \n",
      " 1   ProductionCost        3240 non-null   float64\n",
      " 2   SupplierQuality       3240 non-null   float64\n",
      " 3   DeliveryDelay         3240 non-null   int64  \n",
      " 4   DefectRate            3240 non-null   float64\n",
      " 5   QualityScore          3240 non-null   float64\n",
      " 6   MaintenanceHours      3240 non-null   int64  \n",
      " 7   DowntimePercentage    3240 non-null   float64\n",
      " 8   InventoryTurnover     3240 non-null   float64\n",
      " 9   StockoutRate          3240 non-null   float64\n",
      " 10  WorkerProductivity    3240 non-null   float64\n",
      " 11  SafetyIncidents       3240 non-null   int64  \n",
      " 12  EnergyConsumption     3240 non-null   float64\n",
      " 13  EnergyEfficiency      3240 non-null   float64\n",
      " 14  AdditiveProcessTime   3240 non-null   float64\n",
      " 15  AdditiveMaterialCost  3240 non-null   float64\n",
      " 16  DefectStatus          3240 non-null   int64  \n",
      "dtypes: float64(12), int64(5)\n",
      "memory usage: 430.4 KB\n",
      "\n",
      "--- Análise de Correlação com a 'DefectRate' ---\n",
      "DefectRate              1.000000\n",
      "DefectStatus            0.245746\n",
      "ProductionCost          0.014428\n",
      "SafetyIncidents         0.012196\n",
      "SupplierQuality         0.012157\n",
      "AdditiveMaterialCost    0.011596\n",
      "StockoutRate            0.007547\n",
      "EnergyConsumption       0.005297\n",
      "WorkerProductivity     -0.000388\n",
      "MaintenanceHours       -0.008687\n",
      "DowntimePercentage     -0.011208\n",
      "InventoryTurnover      -0.014148\n",
      "EnergyEfficiency       -0.014168\n",
      "ProductionVolume       -0.019360\n",
      "DeliveryDelay          -0.023024\n",
      "AdditiveProcessTime    -0.028426\n",
      "QualityScore           -0.036350\n",
      "Name: DefectRate, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Carregando o dataset\n",
    "DATA_PATH = 'data/manufacturing_defects.csv'\n",
    "df = pd.read_csv(DATA_PATH)\n",
    "\n",
    "print(\"--- Primeiras 5 linhas do dataset ---\")\n",
    "display(df.head())\n",
    "\n",
    "print(\"\\n--- Informações do dataset ---\")\n",
    "df.info()\n",
    "\n",
    "print(\"\\n--- Análise de Correlação com a 'DefectRate' ---\")\n",
    "print(df.corr(numeric_only=True)[\"DefectRate\"].sort_values(ascending=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Análise Inicial:** A análise de correlação mostra que, com exceção do `DefectStatus` (que é derivado da `DefectRate`), nenhuma outra feature possui uma correlação linear forte com o nosso alvo de regressão. Isso indica que a tarefa de regressão será difícil."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tarefa 1: Regressão - Previsão da `DefectRate`\n",
    "\n",
    "Nesta tarefa, nosso objetivo é prever o valor contínuo da `DefectRate`. Como discutido, as colunas `DefectStatus` e `DefectLevel` são derivadas da `DefectRate` e, portanto, devem ser removidas para evitar vazamento de dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Treinamento do Modelo de Regressão ---\n",
      "Epoch 0, Loss: 12.8206\n",
      "Epoch 500, Loss: 2.3424\n",
      "Epoch 1000, Loss: 2.0665\n",
      "Epoch 1500, Loss: 1.9772\n",
      "Epoch 2000, Loss: 1.9297\n",
      "Epoch 2500, Loss: 1.8964\n",
      "Epoch 3000, Loss: 1.8703\n",
      "Epoch 3500, Loss: 1.8492\n",
      "Epoch 4000, Loss: 1.8309\n",
      "Epoch 4500, Loss: 1.8153\n",
      "\n",
      "--- Resultados da Regressão ---\n",
      "MSE: 2.0317\n",
      "MAE: 1.2137\n",
      "R² Score: -0.2080\n",
      "Taxa de Erro (1 - R²): 1.2080\n"
     ]
    }
   ],
   "source": [
    "# 1.1 Preparação dos Dados\n",
    "X_train_reg, X_test_reg, y_train_reg, y_test_reg = preprocess_data(\n",
    "    df, \"DefectRate\", cols_to_drop=['DefectStatus']\n",
    ")\n",
    "\n",
    "# 1.2 Construção e Treinamento do Modelo\n",
    "print(\"--- Treinamento do Modelo de Regressão ---\")\n",
    "model_reg = NeuralNetwork(\n",
    "    layers=[X_train_reg.shape[1], 32, 16, 1],\n",
    "    activation=\"relu\",\n",
    "    loss_func=mse,\n",
    "    loss_derivative=mse_derivative\n",
    ")\n",
    "# Aumentamos epochs e diminuímos learning rate para ajudar na convergência\n",
    "model_reg.train(X_train_reg, y_train_reg, epochs=5000, learning_rate=0.001, print_every=500)\n",
    "\n",
    "# 1.3 Avaliação do Modelo\n",
    "y_pred_reg = model_reg.predict(X_test_reg).flatten()\n",
    "mse_val = mean_squared_error(y_test_reg, y_pred_reg)\n",
    "mae_val = mean_absolute_error(y_test_reg, y_pred_reg)\n",
    "r2_val = r2_score(y_test_reg, y_pred_reg)\n",
    "regression_error = 1 - r2_val\n",
    "\n",
    "print(\"\\n--- Resultados da Regressão ---\")\n",
    "print(f\"MSE: {mse_val:.4f}\")\n",
    "print(f\"MAE: {mae_val:.4f}\")\n",
    "print(f\"R² Score: {r2_val:.4f}\")\n",
    "print(f\"Taxa de Erro (1 - R²): {regression_error:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Análise da Regressão:** Conforme esperado pela análise de correlação, o modelo de regressão apresenta um R² Score negativo. Isso confirma que as features estáticas do dataset não possuem poder preditivo suficiente para a tarefa de alta precisão de prever o valor exato da `DefectRate`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tarefa 2: Classificação Binária - Previsão do `DefectStatus`\n",
    "\n",
    "Aqui, o objetivo foi prever se uma peça tem defeito (1) ou não (0). Removemos a `DefectRate` para evitar vazamento de dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Treinamento do Modelo de Classificação Binária ---\n",
      "Epoch 0, Loss: 0.7494\n",
      "Epoch 100, Loss: 0.5181\n",
      "Epoch 200, Loss: 0.4602\n",
      "Epoch 300, Loss: 0.4385\n",
      "Epoch 400, Loss: 0.4268\n",
      "\n",
      "--- Resultados da Classificação Binária ---\n",
      "Acurácia: 0.8102\n",
      "Taxa de Erro: 0.1898\n"
     ]
    }
   ],
   "source": [
    "# 2.1 Preparação dos Dados\n",
    "X_train_bin, X_test_bin, y_train_bin, y_test_bin = preprocess_data(\n",
    "    df, \"DefectStatus\", cols_to_drop=['DefectRate'], stratify=True\n",
    ")\n",
    "\n",
    "# 2.2 Construção e Treinamento do Modelo\n",
    "print(\"\\n--- Treinamento do Modelo de Classificação Binária ---\")\n",
    "model_bin = NeuralNetwork(\n",
    "    layers=[X_train_bin.shape[1], 20, 1],\n",
    "    activation=\"relu\",\n",
    "    loss_func=binary_cross_entropy,\n",
    "    loss_derivative=bce_derivative\n",
    ")\n",
    "model_bin.train(X_train_bin, y_train_bin, epochs=500, learning_rate=0.005, print_every=100)\n",
    "\n",
    "# 2.3 Avaliação do Modelo\n",
    "y_pred_prob = model_bin.predict(X_test_bin)\n",
    "y_pred_bin = (y_pred_prob >= 0.5).astype(int)\n",
    "\n",
    "binary_acc = accuracy_score(y_test_bin, y_pred_bin)\n",
    "binary_error = 1 - binary_acc\n",
    "\n",
    "print(\"\\n--- Resultados da Classificação Binária ---\")\n",
    "print(f\"Acurácia: {binary_acc:.4f}\")\n",
    "print(f\"Taxa de Erro: {binary_error:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Análise da Classificação Binária:** O modelo obteve um desempenho significativamente melhor nesta tarefa. Isso demonstra que, embora os dados não sejam bons para prever o valor exato da taxa de defeitos, eles contêm informação suficiente para a tarefa mais simples de classificar uma peça como defeituosa ou não."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tarefa 3: Classificação Multiclasse - Previsão do `DefectLevel`\n",
    "\n",
    "Nesta etapa final, classificamos os defeitos em três níveis (baixo, médio, alto). Primeiro, criamos essa coluna e, em seguida, treinamos o modelo, lembrando de remover as colunas que vazam informação."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Treinamento do Modelo de Classificação Multiclasse ---\n",
      "Epoch 0, Loss: 0.6157\n",
      "Epoch 100, Loss: 0.3029\n",
      "Epoch 200, Loss: 0.2442\n",
      "Epoch 300, Loss: 0.2310\n",
      "Epoch 400, Loss: 0.2264\n",
      "Epoch 500, Loss: 0.2242\n",
      "Epoch 600, Loss: 0.2229\n",
      "Epoch 700, Loss: 0.2221\n",
      "Epoch 800, Loss: 0.2214\n",
      "Epoch 900, Loss: 0.2209\n",
      "\n",
      "--- Resultados da Classificação Multiclasse ---\n",
      "Acurácia: 0.4429\n",
      "Taxa de Erro: 0.5571\n"
     ]
    }
   ],
   "source": [
    "# 3.1 Criação da Coluna Alvo\n",
    "df_multi = df.copy()\n",
    "df_multi[\"DefectLevel\"] = df_multi[\"DefectRate\"].apply(lambda r: 0 if r < 1.5 else 1 if r < 3.0 else 2)\n",
    "\n",
    "# 3.2 Preparação dos Dados\n",
    "X = df_multi.drop(columns=['DefectRate', 'DefectStatus', 'DefectLevel'])\n",
    "y = df_multi['DefectLevel']\n",
    "\n",
    "X_scaled = StandardScaler().fit_transform(X)\n",
    "y_encoded = pd.get_dummies(y).values\n",
    "\n",
    "X_train_multi, X_test_multi, y_train_multi, y_test_multi = train_test_split(\n",
    "    X_scaled, y_encoded, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# 3.3 Construção e Treinamento do Modelo\n",
    "print(\"\\n--- Treinamento do Modelo de Classificação Multiclasse ---\")\n",
    "#TODO\n",
    "model_multi = NeuralNetwork(\n",
    "    layers=[X_train_multi.shape[1], 20, 3],\n",
    "    activation=\"tanh\",\n",
    "    loss_func=mse,\n",
    "    loss_derivative=mse_derivative\n",
    ")\n",
    "model_multi.train(X_train_multi, y_train_multi, epochs=1000, learning_rate=0.01)\n",
    "\n",
    "# 3.4 Avaliação do Modelo\n",
    "y_pred_multi_logits = model_multi.predict(X_test_multi)\n",
    "y_pred_labels = np.argmax(y_pred_multi_logits, axis=1)\n",
    "y_test_labels = np.argmax(y_test_multi, axis=1)\n",
    "\n",
    "multi_acc = accuracy_score(y_test_labels, y_pred_labels)\n",
    "multi_error = 1 - multi_acc\n",
    "\n",
    "print(\"\\n--- Resultados da Classificação Multiclasse ---\")\n",
    "print(f\"Acurácia: {multi_acc:.4f}\")\n",
    "print(f\"Taxa de Erro: {multi_error:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusão Geral do Projeto\n",
    "\n",
    "Este projeto demonstrou com sucesso a implementação de uma rede neural a partir do zero e sua aplicação em diferentes tarefas de machine learning.\n",
    "\n",
    "Conclusões:\n",
    "\n",
    "1.  **Implementação Funcional:** A classe `NeuralNetwork` e suas funções auxiliares foram capazes de treinar modelos para as três tarefas propostas.\n",
    "2.  **Desempenho Depende da Tarefa:** A análise dos resultados revelou que a utilidade do dataset é altamente dependente da complexidade da pergunta. Enquanto as tarefas de **classificação** (binária e multiclasse) obtiveram sucesso, a tarefa de **regressão** falhou.\n",
    "3.  **Limitação dos Dados:** A falha do modelo de regressão foi atribuída à falta de features com forte poder preditivo no dataset, uma conclusão suportada pela análise de correlação.\n",
    "4.  **Próximos Passos:** Para melhorar os modelos, especialmente o de regressão, seria necessário enriquecer o dataset com novas features, como **features temporais** (e.g., média móvel de defeitos), que capturariam a dinâmica da linha de produção, um fator não presente nos dados estáticos atuais."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
